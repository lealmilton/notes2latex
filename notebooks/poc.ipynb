{
   "cells": [
      {
         "cell_type": "code",
         "execution_count": 1,
         "metadata": {},
         "outputs": [],
         "source": [
            "import sys\n",
            "sys.path.append(\"..\")\n",
            "import os\n",
            "\n",
            "from src.image_processing.image_utils import convert_pdf_to_png\n",
            "from src.image_processing.ocr import process_png_images\n",
            "from src.text_processing.text_utils import concatenate_text_files, count_tokens, read_file, save_to_file\n",
            "from src.text_processing.reasoning import gpt4_completion, check_and_correct_latex\n",
            "from src.pdf_generation.pdf_creator import convert_md_to_pdf\n",
            "from src.utils.prompts import PROMPT_MD, PROMPT_CHECK_LATEX\n",
            "\n",
            "api_key = os.getenv('OPENAI_API_KEY')"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "# Turn PDF into separate pngs (one per pdf page)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 5,
         "metadata": {},
         "outputs": [],
         "source": [
            "pdf_path = '../data/notes/aula13_full.pdf'  # Replace with your PDF file path\n",
            "poppler_path = r'../venv/poppler-23.11.0/Library/bin'  # Specify your Poppler bin path\n",
            "\n",
            "convert_pdf_to_png(pdf_path, poppler_path)"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "# Extract text from image"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 6,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "../data/processed/aula13_full/pngs/1.png\n",
                  "Processed and saved OCR text for: 1.png\n",
                  "../data/processed/aula13_full/pngs/2.png\n",
                  "Processed and saved OCR text for: 2.png\n",
                  "../data/processed/aula13_full/pngs/3.png\n",
                  "Processed and saved OCR text for: 3.png\n",
                  "../data/processed/aula13_full/pngs/4.png\n",
                  "Processed and saved OCR text for: 4.png\n",
                  "../data/processed/aula13_full/pngs/5.png\n",
                  "Processed and saved OCR text for: 5.png\n",
                  "../data/processed/aula13_full/pngs/6.png\n",
                  "Processed and saved OCR text for: 6.png\n",
                  "../data/processed/aula13_full/pngs/7.png\n",
                  "Processed and saved OCR text for: 7.png\n",
                  "../data/processed/aula13_full/pngs/8.png\n",
                  "Processed and saved OCR text for: 8.png\n",
                  "../data/processed/aula13_full/pngs/9.png\n",
                  "Processed and saved OCR text for: 9.png\n",
                  "../data/processed/aula13_full/pngs/10.png\n",
                  "Processed and saved OCR text for: 10.png\n",
                  "../data/processed/aula13_full/pngs/11.png\n",
                  "Processed and saved OCR text for: 11.png\n",
                  "../data/processed/aula13_full/pngs/12.png\n",
                  "Processed and saved OCR text for: 12.png\n"
               ]
            }
         ],
         "source": [
            "png_folder_path = \"../data/processed/aula13_full/pngs/\"\n",
            "ocr_text_folder = \"../data/processed/aula13_full/ocr_text/\"\n",
            "\n",
            "process_png_images(png_folder_path, ocr_text_folder)"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "# Concatenate descriptions"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 3,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "All text files have been concatenated into '../data/processed/aula13_full/combined_text.txt'.\n"
               ]
            }
         ],
         "source": [
            "ocr_text_folder = \"../data/processed/aula13_full/ocr_text\"\n",
            "output_file_path = \"../data/processed/aula13_full/combined_text.txt\"\n",
            "\n",
            "concatenate_text_files(ocr_text_folder, output_file_path)\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "# Create Tex"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 2,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "TOTAL TOKENS: 4793\n",
                  "Formatted notes saved to ../data/processed/aula13_full/formatted_notes.tex\n"
               ]
            }
         ],
         "source": [
            "token_threshold = 5500  # Adjust as needed\n",
            "\n",
            "# File paths\n",
            "input_file_path = \"../data/processed/aula13_full/combined_text.txt\"\n",
            "output_file_path = \"../data/processed/aula13_full/formatted_notes.tex\"\n",
            "\n",
            "file_content = read_file(input_file_path)\n",
            "total_tokens = count_tokens(file_content)\n",
            "print(\"TOTAL TOKENS:\", total_tokens)\n",
            "\n",
            "# Check size\n",
            "if total_tokens <= token_threshold:\n",
            "    # Process in one go\n",
            "    response = gpt4_completion(\"\", file_content, PROMPT_MD)\n",
            "else:\n",
            "    print(\"File is too large. Try with a smaller one.\")\n",
            "\n",
            "save_to_file(output_file_path, response)\n",
            "print(f\"Formatted notes saved to {output_file_path}\")"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "# Clean LaTeX output"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 4,
         "metadata": {},
         "outputs": [],
         "source": [
            "def clean_and_overwrite_latex_file(file_path):\n",
            "    unwanted_start = \"```latex\"\n",
            "    unwanted_end = \"```\"\n",
            "\n",
            "    # Read the content of the file\n",
            "    with open(file_path, 'r', encoding='utf-8') as file:\n",
            "        content = file.read()\n",
            "\n",
            "    # Strip off the unwanted markdown from the start and end of the LaTeX content\n",
            "    if content.startswith(unwanted_start):\n",
            "        content = content[len(unwanted_start):].strip()\n",
            "    if content.endswith(unwanted_end):\n",
            "        content = content[:-len(unwanted_end)].strip()\n",
            "\n",
            "    # Overwrite the file with the cleaned content\n",
            "    with open(file_path, 'w', encoding='utf-8') as file:\n",
            "        file.write(content)\n",
            "\n",
            "    return content\n",
            "\n",
            "# File path\n",
            "output_file_path = \"../data/processed/aula13_full/formatted_notes.tex\"\n",
            "\n",
            "# Read, clean, and overwrite the content of the file\n",
            "cleaned_output = clean_and_overwrite_latex_file(output_file_path)"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "# Turn into Tex and/or Check LaTeX\n",
            "\n",
            "Use GPT-4 to check LaTeX syntax"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 2,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "An error occurred: Pandoc died with exitcode \"43\" during conversion: [WARNING] Unusual conversion: to convert a .tex file to PDF, you get better results by using pdflatex (or lualatex or xelatex) directly, try `pdflatex ../data/processed/aula13_full/formatted_notes.tex` instead of `pandoc ../data/processed/aula13_full/formatted_notes.tex -o ../data/processed/aula13_full/formatted_notes.pdf`.\n",
                  "pdflatex: major issue: So far, you have not checked for MiKTeX updates.\n",
                  "pdflatex: major issue: So far, you have not checked for MiKTeX updates.\n",
                  "Error producing PDF.\n",
                  "! Undefined control sequence.\n",
                  "l.89   Defining the matrix \\[M(t) \\coloneqq\n",
                  "\n",
                  "\n",
                  "Correcting LaTeX errors...\n",
                  "Retrying PDF generation...\n"
               ]
            },
            {
               "name": "stderr",
               "output_type": "stream",
               "text": [
                  "[WARNING] Unusual conversion: to convert a .tex file to PDF, you get better results by using pdflatex (or lualatex or xelatex) directly, try `pdflatex ../data/processed/aula13_full/formatted_notes.tex` instead of `pandoc ../data/processed/aula13_full/formatted_notes.tex -o ../data/processed/aula13_full/formatted_notes.pdf`.\n",
                  "pdflatex: major issue: So far, you have not checked for MiKTeX updates.\n",
                  "pdflatex: major issue: So far, you have not checked for MiKTeX updates.\n",
                  "\n"
               ]
            },
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "PDF successfully created at ../data/processed/aula13_full/formatted_notes.pdf\n"
               ]
            }
         ],
         "source": [
            "input_md_file = \"../data/processed/aula13_full/formatted_notes.tex\"\n",
            "output_pdf_file = \"../data/processed/aula13_full/formatted_notes.pdf\"\n",
            "\n",
            "success, error_message = convert_md_to_pdf(input_md_file, output_pdf_file)\n",
            "\n",
            "if not success:\n",
            "    print(\"Correcting LaTeX errors...\")\n",
            "    check_and_correct_latex(input_md_file, error_message)\n",
            "    print(\"Retrying PDF generation...\")\n",
            "    convert_md_to_pdf(input_md_file, output_pdf_file)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 7,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "Formatted notes saved to ../data/processed/aula13_full/formatted_notes.tex\n"
               ]
            }
         ],
         "source": [
            "input_file_path = \"../data/processed/aula13_full/formatted_notes.tex\"\n",
            "output_file_path = \"../data/processed/aula13_full/formatted_notes.tex\"\n",
            "\n",
            "# Read and measure the text\n",
            "file_content = read_file(input_file_path)\n",
            "\n",
            "response = gpt4_completion(\"\", file_content, PROMPT_CHECK_LATEX)\n",
            "\n",
            "# Save the response\n",
            "save_to_file(output_file_path, response)\n",
            "print(f\"Formatted notes saved to {output_file_path}\")"
         ]
      }
   ],
   "metadata": {
      "kernelspec": {
         "display_name": "base",
         "language": "python",
         "name": "python3"
      },
      "language_info": {
         "codemirror_mode": {
            "name": "ipython",
            "version": 3
         },
         "file_extension": ".py",
         "mimetype": "text/x-python",
         "name": "python",
         "nbconvert_exporter": "python",
         "pygments_lexer": "ipython3",
         "version": "3.11.5"
      }
   },
   "nbformat": 4,
   "nbformat_minor": 2
}
