{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Turn PDF into separate pngs (one per pdf page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdf2image import convert_from_path\n",
    "import os\n",
    "\n",
    "def convert_pdf_to_png(pdf_path, poppler_path):\n",
    "    # Extracting the base name of the PDF file to name the folder\n",
    "    base_name = os.path.splitext(os.path.basename(pdf_path))[0]\n",
    "\n",
    "    # Creating the main directory inside 'data/processed/'\n",
    "    main_output_folder = os.path.join('../data', 'processed', base_name)\n",
    "    if not os.path.exists(main_output_folder):\n",
    "        os.makedirs(main_output_folder)\n",
    "\n",
    "    # Creating a sub-directory for PNG files\n",
    "    png_output_folder = os.path.join(main_output_folder, 'pngs')\n",
    "    if not os.path.exists(png_output_folder):\n",
    "        os.makedirs(png_output_folder)\n",
    "\n",
    "    # Convert PDF to a list of images\n",
    "    images = convert_from_path(pdf_path, poppler_path=poppler_path)\n",
    "\n",
    "    # Save each page as a PNG\n",
    "    for i, image in enumerate(images):\n",
    "        image_path = os.path.join(png_output_folder, f'{i + 1}.png')\n",
    "        image.save(image_path, 'PNG')\n",
    "\n",
    "# Usage\n",
    "pdf_path = '../data/notes/aula13.pdf'  # Replace with your PDF file path\n",
    "poppler_path = r'C:/Users/lealm/Documents/canguru/poppler-23.11.0/Library/bin'  # Specify your Poppler bin path\n",
    "convert_pdf_to_png(pdf_path, poppler_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract text from image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/processed/aula13/pngs/1.png\n",
      "Processed and saved OCR text for: 1.png\n",
      "../data/processed/aula13/pngs/2.png\n",
      "Processed and saved OCR text for: 2.png\n",
      "../data/processed/aula13/pngs/3.png\n",
      "Processed and saved OCR text for: 3.png\n",
      "../data/processed/aula13/pngs/4.png\n",
      "Processed and saved OCR text for: 4.png\n",
      "../data/processed/aula13/pngs/5.png\n",
      "Processed and saved OCR text for: 5.png\n",
      "../data/processed/aula13/pngs/6.png\n",
      "Processed and saved OCR text for: 6.png\n",
      "../data/processed/aula13/pngs/7.png\n",
      "Processed and saved OCR text for: 7.png\n",
      "../data/processed/aula13/pngs/8.png\n",
      "Processed and saved OCR text for: 8.png\n",
      "../data/processed/aula13/pngs/9.png\n",
      "Processed and saved OCR text for: 9.png\n",
      "../data/processed/aula13/pngs/10.png\n",
      "Processed and saved OCR text for: 10.png\n",
      "../data/processed/aula13/pngs/11.png\n",
      "Processed and saved OCR text for: 11.png\n",
      "../data/processed/aula13/pngs/12.png\n",
      "Processed and saved OCR text for: 12.png\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import base64\n",
    "import requests\n",
    "import time\n",
    "\n",
    "api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "def encode_image_to_base64(image_path):\n",
    "    \"\"\"Encodes the image to base64 format.\"\"\"\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        return base64.b64encode(image_file.read()).decode('utf-8')\n",
    "\n",
    "def send_image_to_gpt4v(image_path, prompt):\n",
    "    \"\"\"Sends the image to GPT-4V and retrieves the response.\"\"\"\n",
    "    base64_image = encode_image_to_base64(image_path)\n",
    "\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"Authorization\": f\"Bearer {api_key}\"\n",
    "    }\n",
    "\n",
    "    payload = {\n",
    "        \"model\": \"gpt-4-vision-preview\",\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\n",
    "                        \"type\": \"text\",\n",
    "                        \"text\": prompt\n",
    "                    },\n",
    "                    {\n",
    "                        \"type\": \"image_url\",\n",
    "                        \"image_url\": {\n",
    "                            \"url\": f\"data:image/png;base64,{base64_image}\"\n",
    "                        }\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "        ],\n",
    "        \"max_tokens\": 4000\n",
    "    }\n",
    "\n",
    "    response = requests.post(\"https://api.openai.com/v1/chat/completions\", headers=headers, json=payload)\n",
    "    return response.json()\n",
    "\n",
    "def get_previous_description(ocr_text_folder, current_file_index):\n",
    "    \"\"\"Retrieves the previous description from the OCR text files.\"\"\"\n",
    "    previous_file_index = current_file_index - 1\n",
    "    if previous_file_index > 0:\n",
    "        previous_file_name = f\"{previous_file_index}.txt\"\n",
    "        previous_file_path = os.path.join(ocr_text_folder, previous_file_name)\n",
    "        if os.path.exists(previous_file_path):\n",
    "            with open(previous_file_path, 'r', encoding='utf-8') as file:\n",
    "                return file.read()\n",
    "    return \"\"\n",
    "\n",
    "def create_prompt_with_previous_description(previous_description):\n",
    "    \"\"\"Cria um prompt para o GPT-4V que inclui a descrição da página anterior ou lida com o início das anotações.\"\"\"\n",
    "    if previous_description:\n",
    "        previous_notes_context = f\"Baseado nas notas anteriores fornecidas, que são: '{previous_description}',\"\n",
    "    else:\n",
    "        previous_notes_context = \"Parece ser a primeira página de anotações manuscritas, sem conteúdo anterior para referência.\"\n",
    "\n",
    "    prompt = (\n",
    "        f\"{previous_notes_context} você agora receberá uma imagem de anotações manuscritas de um curso de Matemática. \"\n",
    "        f\"Após o texto, seguirá uma imagem. Sua tarefa é processar esta imagem em duas partes:\\n\\n\"\n",
    "        f\"##OBSERVAÇÕES##\\n\"\n",
    "        f\"Forneça considerações gerais sobre o conteúdo na imagem. Descreva quaisquer gráficos, desenhos ou elementos que não estejam claramente distinguíveis. \"\n",
    "        f\"Inclua sua compreensão do contexto do conteúdo, especialmente se ele se relacionar ou contrastar com quaisquer notas anteriores. Mencione qualquer coisa que possa ser omitida durante a transcrição.\\n\\n\"\n",
    "        f\"##TRANSCRIÇÃO EFETIVA##\\n\"\n",
    "        f\"Transcreva todo o conteúdo visível da imagem. Converta todas as expressões matemáticas e equações para o formato LaTeX adequado. \"\n",
    "        f\"Inclua cada pedaço de texto, garantindo que a transcrição seja o mais precisa e completa possível.\"\n",
    "    )\n",
    "    return prompt\n",
    "\n",
    "def process_png_images(folder_path, output_folder):\n",
    "    \"\"\"Processes all PNG images in the specified folder and saves the extracted text.\"\"\"\n",
    "    files = os.listdir(folder_path)\n",
    "    png_files = [file for file in files if file.endswith('.png')]\n",
    "    png_files_sorted = sorted(png_files, key=lambda x: int(x.split('.')[0]))\n",
    "\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    for file_index, file in enumerate(png_files_sorted, start=1):\n",
    "        image_path = os.path.join(folder_path, file)\n",
    "        print(image_path)\n",
    "        #break\n",
    "        previous_description = get_previous_description(ocr_text_folder, file_index)\n",
    "        prompt = create_prompt_with_previous_description(previous_description)\n",
    "        response = send_image_to_gpt4v(image_path, prompt)\n",
    "        time.sleep(15)\n",
    "        \n",
    "        extracted_text = response.get('choices', [{}])[0].get('message', {}).get('content', 'No text found')\n",
    "        output_file_path = os.path.join(output_folder, file.replace('.png', '.txt'))\n",
    "        with open(output_file_path, 'w', encoding='utf-8') as output_file:\n",
    "            output_file.write(extracted_text)\n",
    "\n",
    "        print(f\"Processed and saved OCR text for: {file}\")\n",
    "\n",
    "# Paths to the folders\n",
    "png_folder_path = \"../data/processed/aula13/pngs/\"\n",
    "ocr_text_folder = \"../data/processed/aula13/ocr_text/\"\n",
    "\n",
    "# Process the images\n",
    "process_png_images(png_folder_path, ocr_text_folder)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concatenate descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All text files have been concatenated into '../data/processed/aula13/combined_text.txt'.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def concatenate_text_files(ocr_text_folder, output_file_path):\n",
    "    \"\"\"\n",
    "    Reads all .txt files in the specified folder and concatenates their content into a single file.\n",
    "\n",
    "    Parameters:\n",
    "    ocr_text_folder (str): The folder containing the .txt files.\n",
    "    output_file_path (str): The path of the output file where the concatenated text will be saved.\n",
    "    \"\"\"\n",
    "    # Ensure the folder exists\n",
    "    if not os.path.exists(ocr_text_folder):\n",
    "        print(f\"The specified folder '{ocr_text_folder}' does not exist.\")\n",
    "        return\n",
    "\n",
    "    # Get all .txt files in the folder\n",
    "    txt_files = sorted(f for f in os.listdir(ocr_text_folder) if f.endswith('.txt'))\n",
    "\n",
    "    # Concatenate the contents of each file\n",
    "    concatenated_text = ''\n",
    "    for file in txt_files:\n",
    "        file_path = os.path.join(ocr_text_folder, file)\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            concatenated_text += f.read() + '\\n'  # Add a newline character between files for clarity\n",
    "\n",
    "    # Write the concatenated text to the output file\n",
    "    with open(output_file_path, 'w', encoding='utf-8') as output_file:\n",
    "        output_file.write(concatenated_text)\n",
    "\n",
    "    print(f\"All text files have been concatenated into '{output_file_path}'.\")\n",
    "\n",
    "# Example usage\n",
    "ocr_text_folder = \"../data/processed/aula13/ocr_text\"\n",
    "output_file_path = \"../data/processed/aula13/combined_text.txt\"\n",
    "concatenate_text_files(ocr_text_folder, output_file_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Formatted notes saved to ../data/processed/aula13/formatted_notes.md\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "def read_file(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        return file.read()\n",
    "\n",
    "def gpt4_completion(file_content, prompt):\n",
    "    client = OpenAI()  # Initialize the OpenAI client\n",
    "\n",
    "    full_prompt = file_content + \"\\n\\n\" + prompt  # Combine file content and prompt\n",
    "\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-4-1106-preview\",  # Specify the GPT-4 model\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a math editor.\"},\n",
    "            {\"role\": \"user\", \"content\": full_prompt}\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Extracting the response from the completion\n",
    "    response = completion.choices[0].message.content\n",
    "\n",
    "    return response\n",
    "\n",
    "def save_to_file(file_path, content):\n",
    "    with open(file_path, 'w', encoding='utf-8') as file:\n",
    "        file.write(content)\n",
    "\n",
    "# Example usage\n",
    "input_file_path = \"../data/processed/aula13/combined_text.txt\"\n",
    "output_file_path = \"../data/processed/aula13/formatted_notes.md\"\n",
    "\n",
    "file_content = read_file(input_file_path)\n",
    "\n",
    "prompt = \"Dadas as anotações acima, crie uma versão limpa, bem elaborada e completamente fiel às anotações originais dessas notas de aula, mas faça isso em Inglês. \\\n",
    "    Seu output deve estar em linguagem Markdown, incluindo todo o código LaTeX quando necessário \\\n",
    "        e títulos e subtítulos apropriados. Cheque seu trabalho ao final e corrija qualquer erro de Latex. Lembre-se o output final é em Inglês. Verifique que não existe nenhum erro de Latex. Nao inclua as observações. Apenas um texto limpo em ingles em Markdown.\"\n",
    "\n",
    "response = gpt4_completion(file_content, prompt)\n",
    "\n",
    "# Save the response to a file\n",
    "save_to_file(output_file_path, response)\n",
    "\n",
    "print(f\"Formatted notes saved to {output_file_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check LaTeX\n",
    "\n",
    "Use GPT-4 to check LaTeX syntax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Turn MarkDown into PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred: Pandoc died with exitcode \"43\" during conversion: pdflatex: major issue: So far, you have not checked for MiKTeX updates.\n",
      "pdflatex: major issue: So far, you have not checked for MiKTeX updates.\n",
      "Error producing PDF.\n",
      "! Package amsmath Error: \\dot allowed only in math mode.\n",
      "\n",
      "See the amsmath package documentation for explanation.\n",
      "Type  H <return>  for immediate help.\n",
      " ...                                              \n",
      "                                                  \n",
      "l.62 A System {[} \\dot{x}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pypandoc\n",
    "\n",
    "# This will download Pandoc to a location accessible by pypandoc\n",
    "pypandoc.download_pandoc()\n",
    "\n",
    "def convert_md_to_pdf(input_file_path, output_file_path):\n",
    "    try:\n",
    "        # Convert Markdown to PDF\n",
    "        pypandoc.convert_file(input_file_path, 'pdf', outputfile=output_file_path)\n",
    "        print(f\"PDF successfully created at {output_file_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "# Example usage\n",
    "input_md_file = \"../data/processed/aula13/formatted_notes.md\"\n",
    "output_pdf_file = \"../data/processed/aula13/formatted_notes.pdf\"\n",
    "\n",
    "convert_md_to_pdf(input_md_file, output_pdf_file)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
